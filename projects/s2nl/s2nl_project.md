<base target="_blank">
### Signal to Noise Loops<br/>

#### Project Overview<br/>
Signal to Noise Loops emerged from a broader project entitled 'Auditory Display for Large-scale IoT Networks' carried out at the CONNECT Centre Trinity College Dublin. 

The project integrates open data from Internet of Things (IoT) sensor networks in Dublin, Ireland, in a series of experimental music performances and installations. Each piece treats the city, as mediated by the data it produces, as a collaborator in a musical or sonic work. The project is realized through a bespoke generative music system that continues to adapt and expanded as the project evolves. The system is designed in line with principles from the field of Cybernetics to integrate with both the city and the human performer. Thus, the project links electronic music/sonic performance, IoT/Smart City Data, Generative Music techniques, and Cybernetics. Each performance or installation draws data from networks of IoT devices placed around Dublin City. Sensor and network data are mapped to control the parameters of a given performance/installation. How this takes place is mediated by the generative music system. The state of the system is determined by the state of Dublin city, as represented through the IoT sensor data. The system's state in turn determines the musical choices it makes while improvising alongside a human performer. Each performance with the system is unique as it represents a complex array of data relations that describe the state of Dublin City and any given time. The project involved the iterative development of the system with each performance acting as an evaluation after which the system would be expanded and further refined. <br />

#### Iteration 1: Evolving Feedback Loops, Cellular Automata, and Direct Mapping <br/>
This version of the system explored the cybernetic ideas of looping, human-in-the-loop reflexivity, and evolution with cellular automata algorithmic employed to organize sonic content with musical inputs provided via electric guitar performance. Focused on live performance.  

<img src="images/SonicDreams.jpg?raw=true"/>
* [Sonic Dreams 2017 Poster](images/SonicDreams.jpg)

<iframe style="border: 0; width: 100%; height: 120px;" src="https://bandcamp.com/EmbeddedPlayer/album=4081177415/size=large/bgcol=ffffff/linkcol=0687f5/tracklist=false/artwork=small/track=3075108967/transparent=true/" seamless><a href="https://stephenroddy.bandcamp.com/album/signal-to-noise-loops-2">Signal to Noise Loops by Stephen Roddy</a></iframe>
<br />
<div style="text-align: center;">
<span style="font-weight: normal;">
Dublin City Noise Loops&nbsp;</span></div>
<div style="text-align: center;">
<br /></div>


#### Iteration 2: Generative Systems, Musical Interactions, and Richer Data <br/>
Looping developed into a full generative music system with musical interaction via the Lemur for iPad. Richer data streams and reorganization of mapping in terms of Lefebvre's Rhythmanalysis. 


* [xCoAx Performance](images/xcoaxPerformance.jpg)
* [xCoAx Artist Talk](images/xcoax1.jpg)
* [xCoAx Artists Panel](images/xcoax5.jpg)

<img src="images/PosterXcoax.jpg?raw=true"/><br/>
* [xCoAx Poster](images/PosterXcoax.jpg)

<h4>xCoAx paper describing earlier iteration of the system:</h4>
<br />
<iframe frameborder="0" src="https://drive.google.com/file/d/1awK-N8_hdNML3_gH56VgX2g1jtuekjO6/preview" style="height: 500px; width: 600px;"></iframe>
<br />


#### Iteration 3: Toward Emergence through Eurythmia <br/>
Increased data streams with richer mapping to support the emergence of patterns in sound that represented patterns of social and political activity across the city.


<img src="images/csmc2018_concert_performers.jpg.webp?raw=true"/><br/>
* [CSMC2018 Concert Performance](/images/csmc2018_concert_performers.jpg.webp)

* [ISSTA 2018 Programme](/files/ISSTA programme.pdf)
* [CSMC 2018 Concert](files/Concert – CSMC2018.pdf)

<br />
<div style="text-align: center;">
<iframe style="border: 0; width: 100%; height: 120px;" src="https://bandcamp.com/EmbeddedPlayer/album=4081177415/size=large/bgcol=ffffff/linkcol=0687f5/tracklist=false/artwork=small/track=1330097678/transparent=true/" seamless><a href="https://stephenroddy.bandcamp.com/album/signal-to-noise-loops-2">Signal to Noise Loops by Stephen Roddy</a></iframe>Signal to Noise Loops i++</div>
<br />

#### Iteration 4: COVID-19 Crisis Response: Audiovisual Installation <br/>
Moved to an online audiovisual installation format and introduced machine learning techniques in the generative music system. Patterns of activity before and during COVID mapped to generative music parameters to a visual representation of a changing city.

The piece was performed at the [2021 New York Electroacoustic Music Festival](https://nycemf.org/).
You can find the video and concert program below:

<div style="text-align: center;">
<iframe width="560" height="315" src="https://www.youtube.com/embed/f5yggfFRPAA" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div>

[Youtube Link](https://www.youtube.com/watch?v=f5yggfFRPAA)

<div style="text-align: center;">
<iframe frameborder="0" src="https://drive.google.com/file/d/17JsG6ejsXp0xaS7fLn68oP-1kyStzXYM/preview" style="height: 500px; width: 600px;"></iframe>
</div>

[NYCEMF2021 Concert Program](/files/2021-Program-Book.pdf)

The sonic component of Signal to Noise Loops V4 was installed in the listening room at the [International Conference on Computer Music](http://icmc2021.org/) in Santiago Chile in July of 2021.

<img src="images/ICMC Santiago Chile 2021.png?raw=true"/><br/>
[International Computer Music Conference 2021](http://icmc2021.org/program/)

Signal to Noise Loops V4 was performed at the [2021 Audio Mostly Conference](https://audiomostly.com/2021/program/conference-program/) at the University of Trento, Italy.

<div style="text-align: center;">
<iframe frameborder="0" src="https://drive.google.com/file/d/1jqRP-YzONc0cKgIxSpwHkfQi90Cp9Afi/preview" style="height: 500px; width: 600px;"></iframe>
</div>

[Audio Mostly Programme Link](/files/AudioMostly 2021 Programme.pdf).

The sixteenth edition of Culture Night / Oíche Chultúir will take place on Friday 17 September 2021.
Signal to Noise Loops V4 will be presented as an online installation for Oíche Chultúir Bhaile Átha Cliath 2021 (Dublin City Culture Night).

[Signal to Noise Loops V4- Dublin City Culture Night](https://culturenightdublin.ie/event/signal-to-noise-loops-v4-signal-to-noise-loops-v4/)
<br />
<A href="https://culturenightdublin.ie/event/signal-to-noise-loops-v4-signal-to-noise-loops-v4/" target="_blank"><img src="images/Website 4.png?raw=true"/></a><br/>
<br />

Signal to Noise Loops v4 was also featured in Season 3 of the Video Sound Archive. The Video Sound Archive is an online working archive, dedicated to video and sound that emerged during the pandemic. It provides an alternative to festival and exhibition spaces that accounts for the realities of experiencing art in a time of COVID.

[Signal to Noise Loops v4- Video Sound Archive S3 - February 2022](https://www.videosoundarchive.com/submit#image_1-10903455)
<br />
<a href="https://www.videosoundarchive.com/archive-s3" target="_blank"><img src="images/S3_001.jpg?raw=true"/></a><br/>
<br />


Signal to Noise Loops v4 was selected for performance at the concerts for the 27th International Conference on Auditory Display (ICAD 2022), where it won the award for the Best use of sound in a Concert Piece or Demonstration. You can see the conference paper describing some of the technical development of this specific iteration here:

<div style="text-align: center;">
<iframe frameborder="0" src="https://drive.google.com/file/d/1ZMJ243hDl9Odf47Cv6E5UhhAkl1HbVXZ/preview" style="height: 500px; width: 600px;"></iframe>
</div>
<br />

#### Leonardo Article
For a more in-depth discussion of the first four iterations of this project please see my article in Volume 56 Issue 1 of Leonardo where they are analyzed and contextualized in detail. 

- [ Signal to Noise Loops: A Cybernetic Approach to Musical Performance with Smart City Data and Generative Music Techniques ](https://direct.mit.edu/leon/article-abstract/56/1/87/112358/Signal-to-Noise-Loops-A-Cybernetic-Approach-to)


#### Iteration 5: An Audiovisual Re-emergence<br/>
Audiovisual installation for headphones and mobile devices, reflecting on the mediation of human relationships through networked communications technology both and after the pandemic.

<br />
<a href="https://imma.ie/whats-on/earth-rising-2023/" target="_blank"><img src="images/IMMA_ECO_S.png?raw=true"/></a><br/>
<br />
<a href="" target="_blank"><img src="images/redacted.png?raw=true"/></a><br/>
<br />
<br />

### Technical Aside: Controlling the Proportion of Information Present in a Sonification Signal. 
From time to time in the development of a complex creative and technical project, problems will emerge that require the design of a bespoke solution which may hold some novelty in and of itself. In the case of this project, one such problem was the need to control the proportion of information present in a sonified signal at any given time so that the data could be 'turned up or down' in the same manner that the volume might be.  
This is a tricky problem as the information in a given sonification is a function of the mapping of the data to acoustic parameters and the ensuing perception and interpretation of those acoustic pressure waves as sounds by the listener.   
However, I found that implementing a pre-sonification smoothing filter on the data in a time series sonification smoothes out rapidly varying components of the data, essentially reducing the proportion of information reaching the listener's ears. I formalized this solution and created a technical implementation in Max/MSP that can be integrated into sonification production/performance workflows in Max and Ableton Live.   
A key advantage of this approach to controlling the proportion of information in a sonification is that turning up the data allows you to zoom in on a data set with a sonification to hear small detailed changes. While turning down the data allows you to zoom out to get a sense of evolving trends at higher levels. 
You can read more in the paper below, which was presented at ICAD 2022. 

- [A Technique for Controlling the Proportion of Information in the Sonification of Complex Time Series Data - ICAD 2022](https://www.researchgate.net/publication/361531092_A_Technique_for_Controlling_the_Proportion_of_Information_in_the_Sonification_of_Complex_Time_Series_Data)
 

<!--

### Discussion <br />
The point of mapping data to sound, and more specifically IoT data is to leverage some of the interesting patterns that present themselves across data streams/sets in this manner. Data-driven music is different from sonification where the point is to faithfully communicate or represent the data to the listener. Data-driven music is closer in many ways to algorithmic music composition than it is to sonification because of its focus on finding patterns in the data that might be interesting when mapped to sonic and musical parameters. My previous data-driven music work has employed algorithmic composition techniques and dealt with data from the global financial crash. More recently I have begun to work with IoT data as I believe that the kinds of data we choose to measure and our reasons for measuring them say a lot about what a society values, cares about, and finds interesting while the specific data measurements chronicle the complex interactions between people, the technologies they create and the worlds in which those people and technologies are situated. <br />
<br />
While these explicit points of information may not be directly represented in a performance the rich interleaved patterns of interaction between people, place, and technology are transposed into the sonic realm in each performance. While more abstract and implicit in nature it is the aesthetic dimensionality of these interlocked patterns, which is of interest to me. <br />
<br />
<br />
-->

### Performances:
- [Earth Rising Eco Festival - IMMA 2022](https://imma.ie/whats-on/earth-rising-2023/)
- [The 27th International Conference on Auditory Display Concert](https://icad2022.icad.org/)
- [Signal to Noise Loops v4- Video Sound Archive S3 - February 2022](https://www.videosoundarchive.com/submit#image_1-10903455)
- [Signal to Noise Loops V4- Dublin City Culture Night](https://culturenightdublin.ie/event/signal-to-noise-loops-v4-signal-to-noise-loops-v4/)
- [2021 Audio Mostly Conference](https://audiomostly.com/2021/program/conference-program/)
- [International Computer Music Conference 2021](http://icmc2021.org/program/)
- [2021 New York Electroacoustic Music Festival](https://nycemf.org/)
- [Signal to Noise Loops 3++ @ ISSTA 2018, Derry, September 2018](http://issta.ie/call-2018/)
- [Signal to Noise Loops i2+: Noise Water Dirt @ CSMC 2018, Dublin, August 2018](https://csmc2018.wordpress.com/)
- [Signal to Noise Loops i++ Live @ xCoAx 2018, Madrid](https://2018.xcoax.org/#perf04)
- [Noise Loops for Laptop, Improvised Electric Guitar and Dublin City Noise Level Data @ Sonic Dreams 2017, Sonic Arts Waterford, September 30th 2017](https://1.bp.blogspot.com/-HhZc6oL93Og/W0yMNH4jnVI/AAAAAAAAGFE/VlxW3bOMTlono3rkqbBMtE4XAxElOOgAQCLcBGAs/s1600/Sonic-Dreams-Festival-2017-final-poster-2.jpg)

### Signal to Noise Loops Album
<div style="text-align: center;">
<iframe style="border: 0; width: 350px; height: 470px;" src="https://bandcamp.com/EmbeddedPlayer/album=4081177415/size=large/bgcol=ffffff/linkcol=0687f5/tracklist=false/transparent=true/" seamless><a href="https://stephenroddy.bandcamp.com/album/signal-to-noise-loops-2">Signal to Noise Loops by Stephen Roddy</a></iframe>
</div>

### Tags
Signal to Noise Loops. Cybernetics, Rhythmanallysis, Emergence, Generative Music. IoT Data. Smart Cities. Machine Learning. Cellular Automata.